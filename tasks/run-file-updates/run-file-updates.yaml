---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: run-file-updates
  labels:
    app.kubernetes.io/version: "2.0.2"
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/tags: release
spec:
  description: >-
    Tekton task to run file updates
  params:
    - name: jsonKey
      type: string
      description: The json key containing the file updates
      default: ".spec.data.fileUpdates"
    - name: fileUpdatesPath
      type: string
      description: The path to the file containing the file updates
    - name: snapshotPath
      type: string
      description: Path to the JSON string of the Snapshot spec in the data workspace
    - name: request
      type: string
      description: Name of the request
      default: "process-file-updates"
    - name: synchronously
      type: string
      description: Whether to run synchronously or not
      default: "true"
    - name: pipelineRunUid
      type: string
      description: The uid of the current pipelineRun. Used as a label value when creating internal requests
    - name: resultsDirPath
      description: Path to the results directory in the data workspace
      type: string
  results:
    - name: mergeRequestUrl
      description: URL of MR that was created
  workspaces:
    - name: data
      description: Workspace where the file updates to apply are defined
  steps:
    - name: run-script
      image: quay.io/konflux-ci/release-service-utils:7d0135b80a47cdaa225010ea1e2dff78d057c922
      script: |
        #!/bin/bash
        #
        #
        set -ex

        # Obtain application from snapshot
        application=$(jq -rc .application "$(workspaces.data.path)/$(params.snapshotPath)")

        # Extract the key from the JSON file
        fileUpdates=$(jq -rc "$(params.jsonKey)" "$(workspaces.data.path)/$(params.fileUpdatesPath)")

        TASK_LABEL="internal-services.appstudio.openshift.io/group-id"
        REQUEST_LABEL="internal-services.appstudio.openshift.io/request-id"
        TASK_ID=$(context.taskRun.uid)
        PIPELINERUN_LABEL="internal-services.appstudio.openshift.io/pipelinerun-uid"

        RESULTS_FILE="$(workspaces.data.path)/$(params.resultsDirPath)/file-updates-results.json"
        RESULTS_JSON='{"merge_requests":[]}'

        # empty result to start so result is available
        touch "$(results.mergeRequestUrl.path)"

        # Iterate over the extracted array and call the script
        fileUpdatesLength=$(jq '. | length' <<< "${fileUpdates}")
        for((i=0; i<fileUpdatesLength; i++)); do
          item=$(jq -cr ".[$i]" <<< "${fileUpdates}")

          repo=$(jq -r '.repo' <<< "${item}")
          upstream_repo=$(jq -r '.upstream_repo' <<< "${item}")
          ref=$(jq -r '.ref // "main"' <<< "${item}")
          paths=$(jq -cr '.paths // "[]"' <<< "${item}")
          file_updates_secret=$(jq -r '.file_updates_secret // "file-updates-secret"' <<< "${item}")

          echo "=== Updates for repo: ${repo} ==="

          echo -en "  Evaluating '{{ }}' expressions..."
          updatedPaths=$(update-paths -p "${paths}" -f "$(workspaces.data.path)/$(params.snapshotPath)")
          echo "done"

          echo -en "  Creating InternalRequest to produce file-updates..."
          requestId="$(openssl rand -hex 12)"
          internal-request -r "$(params.request)" \
                           -p upstream_repo="${upstream_repo}" \
                           -p repo="${repo}" \
                           -p ref="${ref}" \
                           -p paths="${updatedPaths}" \
                           -p application="${application}" \
                           -p file_updates_secret="${file_updates_secret}" \
                           -s "$(params.synchronously)" \
                           -l ${TASK_LABEL}="${TASK_ID}" \
                           -l ${REQUEST_LABEL}="${requestId}" \
                           -l "${PIPELINERUN_LABEL}=$(params.pipelineRunUid)"

          IRjson=$(kubectl get internalrequest \
            -l "${PIPELINERUN_LABEL}=$(params.pipelineRunUid),${TASK_LABEL}=${TASK_ID},${REQUEST_LABEL}=${requestId}" \
            -o jsonpath='{.items[0]}' --sort-by=.metadata.creationTimestamp )

          results=$(jq -r '.status.results' <<< "${IRjson}")
          internalRequestPipelineRunName="$(jq -jr '.internalRequestPipelineRunName // ""' <<< "${results}")"
          internalRequestTaskRunName="$(jq -jr '.internalRequestTaskRunName // ""' <<< "${results}")"

          echo "** internalRequestPipelineRunName: ${internalRequestPipelineRunName}"
          echo "** internalRequestTaskRunName: ${internalRequestTaskRunName}"

          if [ "$(jq -jr '.buildState' <<< "${results}")" == "Failed" ]; then
            echo -en "  FileUpdates Error: "
            jq -r '.jsonBuildInfo | fromjson | .error' <<< "${results}"
            echo -e "  Diff (content might be truncated): "
            jq -r '.jsonBuildInfo | fromjson | .str | tostring' <<< "${results}" | awk '{ print "\t"$0 }'
            echo -e "=== Finished ===\n"
            exit 1
          else
            MR=$(jq -r '.jsonBuildInfo | fromjson | fromjson | .merge_request // "unknown"' <<< "${results}")
            echo "MR Created: ${MR}"
            echo "${MR}" >> "$(results.mergeRequestUrl.path)"
            RESULTS_JSON=$(jq --arg i "$i" --arg MR "${MR}" '.merge_requests[$i|tonumber] += {"url": $MR}' \
                <<< "$RESULTS_JSON")
            echo -n "${RESULTS_JSON}" | tee "$RESULTS_FILE"
          fi
          echo -e "=== Finished ===\n"
        done
