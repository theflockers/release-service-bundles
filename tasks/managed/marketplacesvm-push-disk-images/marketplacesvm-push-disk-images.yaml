---
apiVersion: tekton.dev/v1
kind: Task
metadata:
  name: marketplacesvm-push-disk-images
  labels:
    app.kubernetes.io/version: "0.2.0"
  annotations:
    tekton.dev/pipelines.minVersion: "0.12.1"
    tekton.dev/tags: release
spec:
  description: >-
    Tekton task to push disk images to Cloud Marketplaces
  params:
    - name: snapshotPath
      type: string
      description: |
        Path to the JSON string of the mapped snapshot spec in the data workspace.
        It must be processed by the "apply-mapping" task first.
    - name: cloudMarketplacesSecret
      type: string
      description: Env specific secret containing the marketplaces credentials.
    - name: prePush
      type: string
      description: Whether perform a pre-push (true) or not (false). When true it will not publish PROD.
      default: false
    - name: concurrentLimit
      type: string
      description: The maximum number of images to be pulled at once.
      default: 3
  workspaces:
    - name: data
      description: The workspace where the snapshot spec json file resides
  steps:
    - name: pull-and-push-images-to-marketplaces
      image: quay.io/konflux-ci/release-service-utils:6556e8a6b031c1aad4f0472703fd121a6e1cd45d
      env:
        - name: CLOUD_CREDENTIALS
          valueFrom:
            secretKeyRef:
              name: $(params.cloudMarketplacesSecret)
              key: key
      script: |
        #!/usr/bin/env bash
        set -eux

        # Setup required variables
        SNAPSHOT_JSON=$(jq -c '.' "$(workspaces.data.path)/$(params.snapshotPath)")
        STARMAP_MAPPING=$(jq -c '[.components[].starmap[]]' <<< "$SNAPSHOT_JSON")
        STARMAP_MAPPING_FILE="$(workspaces.data.path)/$(dirname "$(params.snapshotPath)")/starmap.yaml"
        yq -p json -o yaml <<< "$STARMAP_MAPPING" > "$STARMAP_MAPPING_FILE"

        BASE_DIR="$(mktemp -d)"
        DISK_IMGS_DIR="${BASE_DIR}/starmap/CLOUD_IMAGES"
        mkdir -p "${DISK_IMGS_DIR}"

        RUNNING_JOBS="\j" # Bash parameter for number of jobs currently running
        NUM_COMPONENTS=$(jq '.components | length' <<< "$SNAPSHOT_JSON")

        prepare_component() { # Expected argument is [component json]
            COMPONENT=$1
            PRODUCT_INFO=$(jq -c '.productInfo' <<< "${COMPONENT}")
            PULLSPEC=$(jq -er '.containerImage' <<< "${COMPONENT}")
            IMG_NAME=$(jq -er '.name' <<< "${COMPONENT}")
            BUILD_NAME=$(jq -er '.productCode' <<< "${PRODUCT_INFO}")
            BUILD_VERSION=$(jq -er '.productVersionName' <<< "${PRODUCT_INFO}")
            BUILD_ARCH=$(jq -er '.staged.files[0].filename' <<< "${COMPONENT}")
            BUILD_ARCH=${BUILD_ARCH%\.*}   # Rstrip on . to remove the extension
            BUILD_ARCH=${BUILD_ARCH##*-}  # Lstrip on - on get the arch
            RESOURCES_JSON='
            {
                "api": "v1",
                "resource": "CloudImage",
                "description": "",
                "boot_mode": "hybrid",
                "build": {},
                "images": []
            }'
            RESOURCES_JSON=$(jq -c \
                            --arg build_name "$BUILD_NAME" \
                            --arg build_arch "$BUILD_ARCH" \
                            --arg build_version "$BUILD_VERSION" \
                            '.build.name=$build_name |
                            .build.arch=$build_arch |
                            .build.version=$build_version' <<< "$RESOURCES_JSON"
            )
            DESTINATION="${DISK_IMGS_DIR}/${IMG_NAME}"
            mkdir -p "${DESTINATION}"
            DOWNLOAD_DIR=$(mktemp -d)
            cd "$DOWNLOAD_DIR"
            # oras has very limited support for selecting the right auth entry,
            # so create a custom auth file with just one entry
            AUTH_FILE=$(mktemp)
            select-oci-auth "${PULLSPEC}" > "$AUTH_FILE"
            oras pull --registry-config "$AUTH_FILE" "$PULLSPEC"
            NUM_MAPPED_FILES=$(jq '.staged.files | length' <<< "${COMPONENT}")
            for ((i = 0; i < NUM_MAPPED_FILES; i++)); do
                FILE=$(jq -c --arg i "$i" '.staged.files[$i|tonumber]' <<< "$COMPONENT")
                SOURCE=$(jq -er '.source' <<< "$FILE")
                FILENAME=$(jq -er '.filename' <<< "$FILE")
                if [ -f "${SOURCE}.gz" ]; then
                    gzip -d "${SOURCE}.gz"
                fi
                if [ -f "${DESTINATION}/${FILENAME}" ]; then
                    echo -n "Multiple files use the same destination value: $DESTINATION" >&2
                    echo " and filename value: $FILENAME. Failing..." >&2
                    exit 1
                fi
                if [ "${FILENAME##*\.}" = "vhd" ]; then
                    image_type="VHD"
                elif [ "${FILENAME##*\.}" = "raw" ]; then
                    image_type="AMI"
                else
                  continue
                fi
                mv "$SOURCE" "${DESTINATION}" || echo "didn't find mapped file: ${SOURCE}"
                RESOURCES_JSON=$(jq --arg filename "$FILENAME" \
                    '.images[.images | length] = {"path": $filename, "architecture": "$arch"}' <<< "$RESOURCES_JSON")
                RESOURCES_JSON=$(jq --arg image_type "$image_type" \
                    '.type = "$image_type"' <<< "$RESOURCES_JSON")
            done
            echo "$RESOURCES_JSON" | yq -P -I 4 > "$DESTINATION/resources.yaml"
        }

        # Process each component in parallel
        for ((i = 0; i < NUM_COMPONENTS; i++)); do
            COMPONENT=$(jq -c --arg i "$i" '.components[$i|tonumber]' <<< "$SNAPSHOT_JSON")
            # Limit batch size to concurrent limit
            while (( ${RUNNING_JOBS@P} >= $(params.concurrentLimit) )); do
                wait -n
            done
            prepare_component "$COMPONENT" &
        done

        # Wait for remaining processes to finish
        while (( ${RUNNING_JOBS@P} > 0 )); do
            wait -n
        done

        # Change to the base directory
        cd "${BASE_DIR}"

        # Validate the staged structure using pushsource-ls
        pushsource-ls "staged:${BASE_DIR}"

        # Process the push
        EXTRA_ARGS=()
        if [[ "$(params.prePush)" == "true" ]]; then
             EXTRA_ARGS+=("--nochannel")
        fi
        marketplacesvm_push_wrapper --debug "${EXTRA_ARGS[@]}" \
            --source "${BASE_DIR}" --starmap-file "$STARMAP_MAPPING_FILE"
